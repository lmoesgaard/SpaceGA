{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2b7630",
   "metadata": {},
   "source": [
    "Notebook for setting up and runnning active learning (AL). The scoring function selected below is DockSearch (trying to optimize AutoDock-GPU docking scores), but it can be switched for LogPSearch or FPSearch if desired. Just remember to switch the scoring inputs as well. Before runnning, please ensure that fingeprint.npz and SMILES.parquet files are available. The data/convert.py is available to demonstrate the conversion of space separated .smi files. Please also ensure that AutoDock-GPU and the GPU implementation of torch are installed and availabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List\n",
    "\n",
    "from setup import save_config\n",
    "from main import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036aa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class datasettings():\n",
    "    O: bool = True # Overwrite\n",
    "    o: str = '/path/to/output' # Directory to store output files\n",
    "    i: str = \"data\"  # location of the directories 'smis' and 'fps'\n",
    "    config: str = 'json_files/config.json' # Name of configuration file that will be written\n",
    "    p_size: int = 10000 # Population size\n",
    "    iterations: int = 10 # Number of iterations\n",
    "    model_name: str = \"NN1\" # Name of model class in ml/models.py\n",
    "    cpu: int = 64 # Number of CPUs to use\n",
    "    gpu: int = 8  # Number of GPUs to use\n",
    "    maxmodels: int = 1 # Max number of models to run on each GPU for prediction\n",
    "    bsize: int = 512 # Batch size when training the model\n",
    "    init_split: List[float] = field(default_factory=lambda: [0.8, 0.1, 0.1]) # how to split data into train/val/test set after first iteration\n",
    "    mode: str = 'DockSearch'  # FPSearch, LogPSearch, DockSearch\n",
    "    scoring_inputs: Dict[str, str] = field(default_factory=lambda: {\"fld_file\": \"/path/to/fld_file.fld\", \n",
    "                                                                    \"autodock\": \"/path/to/autodock_gpu\", # Path to AutoDock-GPU executable\n",
    "                                                                    \"workdir\": \"/path/to/output\", # Can be any scratch location\n",
    "                                                                    \"obabel\": \"/path/to/obabel\", # Path to obabel executable \n",
    "                                                                   }\n",
    "                                           ) # Inputs required for the scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b0c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = datasettings()\n",
    "save_config(settings)\n",
    "out = main(\"AL\", settings.config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
